# Hard ROC
# A receiver operating characteristic curve, or ROC curve, 
# is a graphical plot that illustrates the performance of a 
# binary classifier model (can be used for multi class classification as well) 
# at varying threshold values.

# The ROC curve is the plot of the true positive rate (TPR) against
#  the false positive rate (FPR) at each threshold setting. 


# The receiver-operator characteristics can be used to quantify how well you
#  can distinguish samples drawn from two different probability distributions.
# Your task is to implement the ROC analysis with your own Python code,
# and to quantify how well you can discriminate between the activity from 
# two neurons firing according to a Poisson statistics

# %%
import numpy as np
import matplotlib.pyplot as plt
import scipy 

# %%
# a) Write a function which takes two Numpy vectors samples1 and samples2 and 
# computes the ROC curve, i.e. how false positives fp(z)
# and true positives tp(z) increase with decreasing decision threshold z 
# (for background info see Decoding chapter in Computational Neurosciences script). 
# Your function shall return two vectors fp and tp.
# For avoiding to lose information by having to choose an arbitrary bin width,
# do not compute histograms from the samples. The challenge for you is to 
# rather compute the ROC curve directly from the sample vectors. 
# Remember: Get a cafe if computing ROC is too hard!

# preparation: (label if not yet done), split data into training and test data

samples_1: list         # original vector 1
samples_2: list         # original vector 2
samples_1_train: list   # training data 1
samples_2_train: list   # training data 2
samples_1_test: list    # testing data 1
samples_2_test: list    # testing data 2
z: float                # decision treshold

true_y: list
est_y: list

# input:
# np vector samples 1
# np vector samples 2
# decision treshold z

# initialize decision treshold z
# calculate fp
#   store
# calculate tp
#   store
# compute ROC curve (how do fp and tp increase with decreasing z?)

def calc_tpr(tp, fn):
    tpr = tp / (tp + fn)
    return tpr

def calc_fpr(fp, tn):
    fpr = fp / (fp + tn)
    return fpr


# def plot_roc_curve(true_y, y_prob):
#    """
#    plots the roc curve based of the probabilities
#    """

#    fpr, tpr, thresholds = roc_curve(true_y, y_prob)
#    plt.plot(fpr, tpr)
#    plt.xlabel('False Positive Rate')
#    plt.ylabel('True Positive Rate') 

# output:
# vector false positives fp
# TP-Rate = True Positives / (True Positives + False Negatives)
# vector true positives tp
# FPR = False Positives / (False Positives + True Negatives)
# plot ROC curve




# %% 
#b) Test your functions on the examples provided in the code snippet roc samples.py. They should result
# in the plots shown on the next page. Make sure that your code detects putative inconsistencies in the
# input, e.g. wrong data types or empty sample vectors. Do some decent error catching if your assertions
# fail!

# %% 
# c) Extend your function by also computing and returning the auroc (i.e., area-under-the ROC curve). The
#auroc provides the classification accuracy given two samples, with one taken from each distribution.

# %% 
# d) Extend your function by also computing and returning acc(z). acc(z) should be the classification
#accuracy acc given one sample, drawn with equal likelihood from one of the two distributions. This
#measure depends on the chosen decision threshold z.

# %%
# e) Apply your function to spike counts generated by two ’Poisson’ neurons firing with constant rates r1
#and r2, respectively, over a time interval T. Show in phase space how classification accuracy with one
#sample (acc) or two samples (auroc) depend on the firing rates. Mark the boundary where accuracy
#surpasses 95% correct.

# %% 
# f) JUST FOR FUN: Extend your ROC function to take two additional input vectors weights1 and
# weights2 which specify how often a specific sample in samples1 and samples2 occur, respectively.
# This gives you the opportunity to compute the ROC for a tabulated distribution function. Re-compute
# the Poisson example for the tabulated distribution, and compare with the sampled distributions for
# different number of samples drawn.